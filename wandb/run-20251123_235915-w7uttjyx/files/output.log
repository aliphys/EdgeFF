Running as part of sweep: qb1z2yhj
Sweep override - layers: [784, 100, 100, 100, 100, 10]
Sweep override - softmax_epochs: 3
Sweep override - train_batch_size: 256
Sweep override - seed: 42
[34m[1mwandb[0m: [33mWARNING[0m Config item 'layers' was locked by 'sweep' (ignored update).
[34m[1mwandb[0m: [33mWARNING[0m Config item 'seed' was locked by 'sweep' (ignored update).
Found INA3221 power monitor at: /sys/bus/i2c/drivers/ina3221/1-0040/hwmon/hwmon1
Started tegrastats monitoring
Hardware monitoring enabled.
Rep Epoch: 1/3 [256/50000 (1%)]
Rep Epoch: 1/3 [2816/50000 (6%)]
Rep Epoch: 1/3 [5376/50000 (11%)]
Rep Epoch: 1/3 [7936/50000 (16%)]
Rep Epoch: 1/3 [10496/50000 (21%)]
Rep Epoch: 1/3 [13056/50000 (26%)]
Rep Epoch: 1/3 [15616/50000 (31%)]
Rep Epoch: 1/3 [18176/50000 (36%)]
Rep Epoch: 1/3 [20736/50000 (41%)]
Rep Epoch: 1/3 [23296/50000 (47%)]
Rep Epoch: 1/3 [25856/50000 (52%)]
Rep Epoch: 1/3 [28416/50000 (57%)]
Rep Epoch: 1/3 [30976/50000 (62%)]
Rep Epoch: 1/3 [33536/50000 (67%)]
Rep Epoch: 1/3 [36096/50000 (72%)]
Rep Epoch: 1/3 [38656/50000 (77%)]
Rep Epoch: 1/3 [41216/50000 (82%)]
Rep Epoch: 1/3 [43776/50000 (88%)]
Rep Epoch: 1/3 [46336/50000 (93%)]
Rep Epoch: 1/3 [48896/50000 (98%)]
Rep Epoch: 2/3 [256/50000 (1%)]
Rep Epoch: 2/3 [2816/50000 (6%)]
Rep Epoch: 2/3 [5376/50000 (11%)]
Rep Epoch: 2/3 [7936/50000 (16%)]
Rep Epoch: 2/3 [10496/50000 (21%)]
Rep Epoch: 2/3 [13056/50000 (26%)]
Rep Epoch: 2/3 [15616/50000 (31%)]
Rep Epoch: 2/3 [18176/50000 (36%)]
Rep Epoch: 2/3 [20736/50000 (41%)]
Rep Epoch: 2/3 [23296/50000 (47%)]
Rep Epoch: 2/3 [25856/50000 (52%)]
Rep Epoch: 2/3 [28416/50000 (57%)]
Rep Epoch: 2/3 [30976/50000 (62%)]
Rep Epoch: 2/3 [33536/50000 (67%)]
Rep Epoch: 2/3 [36096/50000 (72%)]
Rep Epoch: 2/3 [38656/50000 (77%)]
Rep Epoch: 2/3 [41216/50000 (82%)]
Rep Epoch: 2/3 [43776/50000 (88%)]
Rep Epoch: 2/3 [46336/50000 (93%)]
Rep Epoch: 2/3 [48896/50000 (98%)]
Rep Epoch: 3/3 [256/50000 (1%)]
Rep Epoch: 3/3 [2816/50000 (6%)]
Rep Epoch: 3/3 [5376/50000 (11%)]
Rep Epoch: 3/3 [7936/50000 (16%)]
Rep Epoch: 3/3 [10496/50000 (21%)]
Rep Epoch: 3/3 [13056/50000 (26%)]
Rep Epoch: 3/3 [15616/50000 (31%)]
Rep Epoch: 3/3 [18176/50000 (36%)]
Rep Epoch: 3/3 [20736/50000 (41%)]
Rep Epoch: 3/3 [23296/50000 (47%)]
Rep Epoch: 3/3 [25856/50000 (52%)]
Rep Epoch: 3/3 [28416/50000 (57%)]
Rep Epoch: 3/3 [30976/50000 (62%)]
Rep Epoch: 3/3 [33536/50000 (67%)]
Rep Epoch: 3/3 [36096/50000 (72%)]
Rep Epoch: 3/3 [38656/50000 (77%)]
Rep Epoch: 3/3 [41216/50000 (82%)]
Rep Epoch: 3/3 [43776/50000 (88%)]
Rep Epoch: 3/3 [46336/50000 (93%)]
Rep Epoch: 3/3 [48896/50000 (98%)]
Softmax Epoch: 1/3 [256/50000 (1%)]
Softmax Epoch: 1/3 [2816/50000 (6%)]
Softmax Epoch: 1/3 [5376/50000 (11%)]
Softmax Epoch: 1/3 [7936/50000 (16%)]
Softmax Epoch: 1/3 [10496/50000 (21%)]
Softmax Epoch: 1/3 [13056/50000 (26%)]
Softmax Epoch: 1/3 [15616/50000 (31%)]
Softmax Epoch: 1/3 [18176/50000 (36%)]
Softmax Epoch: 1/3 [20736/50000 (41%)]
Softmax Epoch: 1/3 [23296/50000 (47%)]
Softmax Epoch: 1/3 [25856/50000 (52%)]
Softmax Epoch: 1/3 [28416/50000 (57%)]
Softmax Epoch: 1/3 [30976/50000 (62%)]
Softmax Epoch: 1/3 [33536/50000 (67%)]
Softmax Epoch: 1/3 [36096/50000 (72%)]
Softmax Epoch: 1/3 [38656/50000 (77%)]
Softmax Epoch: 1/3 [41216/50000 (82%)]
Softmax Epoch: 1/3 [43776/50000 (88%)]
Softmax Epoch: 1/3 [46336/50000 (93%)]
Softmax Epoch: 1/3 [48896/50000 (98%)]
Softmax Epoch: 2/3 [256/50000 (1%)]
Softmax Epoch: 2/3 [2816/50000 (6%)]
Softmax Epoch: 2/3 [5376/50000 (11%)]
Softmax Epoch: 2/3 [7936/50000 (16%)]
Softmax Epoch: 2/3 [10496/50000 (21%)]
Softmax Epoch: 2/3 [13056/50000 (26%)]
Softmax Epoch: 2/3 [15616/50000 (31%)]
Softmax Epoch: 2/3 [18176/50000 (36%)]
Softmax Epoch: 2/3 [20736/50000 (41%)]
Softmax Epoch: 2/3 [23296/50000 (47%)]
Softmax Epoch: 2/3 [25856/50000 (52%)]
Softmax Epoch: 2/3 [28416/50000 (57%)]
Softmax Epoch: 2/3 [30976/50000 (62%)]
Softmax Epoch: 2/3 [33536/50000 (67%)]
Softmax Epoch: 2/3 [36096/50000 (72%)]
Softmax Epoch: 2/3 [38656/50000 (77%)]
Softmax Epoch: 2/3 [41216/50000 (82%)]
Softmax Epoch: 2/3 [43776/50000 (88%)]
Softmax Epoch: 2/3 [46336/50000 (93%)]
Softmax Epoch: 2/3 [48896/50000 (98%)]
Softmax Epoch: 3/3 [256/50000 (1%)]
Softmax Epoch: 3/3 [2816/50000 (6%)]
Softmax Epoch: 3/3 [5376/50000 (11%)]
Softmax Epoch: 3/3 [7936/50000 (16%)]
Softmax Epoch: 3/3 [10496/50000 (21%)]
Softmax Epoch: 3/3 [13056/50000 (26%)]
Softmax Epoch: 3/3 [15616/50000 (31%)]
Softmax Epoch: 3/3 [18176/50000 (36%)]
Softmax Epoch: 3/3 [20736/50000 (41%)]
Softmax Epoch: 3/3 [23296/50000 (47%)]
Softmax Epoch: 3/3 [25856/50000 (52%)]
Softmax Epoch: 3/3 [28416/50000 (57%)]
Softmax Epoch: 3/3 [30976/50000 (62%)]
Softmax Epoch: 3/3 [33536/50000 (67%)]
Softmax Epoch: 3/3 [36096/50000 (72%)]
Softmax Epoch: 3/3 [38656/50000 (77%)]
Softmax Epoch: 3/3 [41216/50000 (82%)]
Softmax Epoch: 3/3 [43776/50000 (88%)]
Softmax Epoch: 3/3 [46336/50000 (93%)]
Softmax Epoch: 3/3 [48896/50000 (98%)]

Results for the TRAIN set:
	F1-score: 0.09927818738229859
	Accuracy: 0.09992
	Error: 0.9000800028443336

Inference Metrics for TRAIN set:
	Latency per sample: 0.0015 ms
	Energy per sample: 0.0103 mJ
	Average power: 6644.74 mW

Results for the TEST set:
	F1-score: 0.9167926361742156
	Accuracy: 0.9187
	Error: 0.08130002021789551

Inference Metrics for TEST set:
	Latency per sample: 0.0015 ms
	Energy per sample: 0.0099 mJ
	Average power: 6644.74 mW

Results for the VALIDATION set:
	F1-score: 0.9142117632490876
	Accuracy: 0.9162
	Error: 0.08380001783370972

Inference Metrics for VALIDATION set:
	Latency per sample: 0.0015 ms
	Energy per sample: 0.0102 mJ
	Average power: 6644.74 mW
Averaged mean:  6.294709372980956
Averaged std:  1.6151430020344448
Averaged mean_all_incorrect_labels:  -3.940921593739283
Averaged std_all_incorrect_labels:  2.024413943787716
Averaged mean:  7.301157408255979
Averaged std:  1.863685848535661
Averaged mean_all_incorrect_labels:  -4.536234424789329
Averaged std_all_incorrect_labels:  2.3015318056933785
Averaged mean:  9.057542597381001
Averaged std:  2.1016033873944036
Averaged mean_all_incorrect_labels:  -4.33612572236011
Averaged std_all_incorrect_labels:  2.5164399673090725
Averaged mean:  11.586663150295841
Averaged std:  2.320047423260988
Averaged mean_all_incorrect_labels:  -3.557376519916274
Averaged std_all_incorrect_labels:  2.6973209007557037
Averaged mean:  12.229530098797706
Averaged std:  2.4070086073903325
Averaged mean_all_incorrect_labels:  -2.79130066495671
Averaged std_all_incorrect_labels:  2.684159782893116
  0%|                                                                                 | 0/10000 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/jetson/Documents/github/EdgeFF/exploratory/Refractoring_gpu/Main.py", line 410, in <module>
    main()
  File "/home/jetson/Documents/github/EdgeFF/exploratory/Refractoring_gpu/Main.py", line 384, in main
    Evaluation.eval_val_set_light(model, inputs=test_inputs_full, targets=test_targets_full,
  File "/home/jetson/Documents/github/EdgeFF/exploratory/Refractoring_gpu/Evaluation.py", line 91, in eval_val_set_light
    y_predicted[chunk_indices_validation[i]], predicted_with_layers_up_to[chunk_indices_validation[i]] = \
  File "/home/jetson/.local/lib/python3.10/site-packages/torch/_tensor.py", line 1213, in __array__
    return self.numpy().astype(dtype, copy=False)
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
Traceback (most recent call last):
  File "/home/jetson/Documents/github/EdgeFF/exploratory/Refractoring_gpu/Main.py", line 410, in <module>
    main()
  File "/home/jetson/Documents/github/EdgeFF/exploratory/Refractoring_gpu/Main.py", line 384, in main
    Evaluation.eval_val_set_light(model, inputs=test_inputs_full, targets=test_targets_full,
  File "/home/jetson/Documents/github/EdgeFF/exploratory/Refractoring_gpu/Evaluation.py", line 91, in eval_val_set_light
    y_predicted[chunk_indices_validation[i]], predicted_with_layers_up_to[chunk_indices_validation[i]] = \
  File "/home/jetson/.local/lib/python3.10/site-packages/torch/_tensor.py", line 1213, in __array__
    return self.numpy().astype(dtype, copy=False)
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.
