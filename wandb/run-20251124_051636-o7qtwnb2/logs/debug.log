2025-11-24 05:16:36,041 INFO    MainThread:88684 [wandb_setup.py:_flush():80] Current SDK version is 0.23.0
2025-11-24 05:16:36,041 INFO    MainThread:88684 [wandb_setup.py:_flush():80] Configure stats pid to 88684
2025-11-24 05:16:36,041 INFO    MainThread:88684 [wandb_setup.py:_flush():80] Loading settings from /home/jetson/.config/wandb/settings
2025-11-24 05:16:36,041 INFO    MainThread:88684 [wandb_setup.py:_flush():80] Loading settings from /home/jetson/Documents/github/EdgeFF/wandb/settings
2025-11-24 05:16:36,041 INFO    MainThread:88684 [wandb_setup.py:_flush():80] Loading settings from environment variables
2025-11-24 05:16:36,041 INFO    MainThread:88684 [wandb_init.py:setup_run_log_directory():713] Logging user logs to /home/jetson/Documents/github/EdgeFF/wandb/run-20251124_051636-o7qtwnb2/logs/debug.log
2025-11-24 05:16:36,042 INFO    MainThread:88684 [wandb_init.py:setup_run_log_directory():714] Logging internal logs to /home/jetson/Documents/github/EdgeFF/wandb/run-20251124_051636-o7qtwnb2/logs/debug-internal.log
2025-11-24 05:16:36,042 INFO    MainThread:88684 [wandb_init.py:init():840] calling init triggers
2025-11-24 05:16:36,042 INFO    MainThread:88684 [wandb_init.py:init():845] wandb.init called with sweep_config: {'layers': '784,100,10', 'rep-epochs': 10, 'seed': 42, 'softmax-epochs': 10, 'train-batch-size': 512}
config: {'layers': [784, 100, 10], 'representation_epochs': 10, 'softmax_epochs': 10, 'train_batch_size': 512, 'test_batch_size': 512, 'val_size': 10000, 'log_val_samples': 1000, 'final_train_sample': 5000, 'final_val_sample': 2000, 'seed': 42, 'dataset': 'MNIST', 'train_flag': True, 'enable_hw_monitor': True, 'hw_interval_ms': 500, 'device': 'cpu', 'cuda_available': True, 'cuda_device_name': None, '_wandb': {}}
2025-11-24 05:16:36,042 INFO    MainThread:88684 [wandb_init.py:init():888] starting backend
2025-11-24 05:16:36,283 INFO    MainThread:88684 [wandb_init.py:init():891] sending inform_init request
2025-11-24 05:16:36,287 INFO    MainThread:88684 [wandb_init.py:init():899] backend started and connected
2025-11-24 05:16:36,288 INFO    MainThread:88684 [wandb_run.py:_config_callback():1385] config_cb None None {'layers': '784,100,10', 'rep-epochs': 10, 'seed': 42, 'softmax-epochs': 10, 'train-batch-size': 512}
2025-11-24 05:16:36,289 INFO    MainThread:88684 [wandb_init.py:init():969] updated telemetry
2025-11-24 05:16:36,297 INFO    MainThread:88684 [wandb_init.py:init():993] communicating run to backend with 600.0 second timeout
2025-11-24 05:16:36,933 INFO    MainThread:88684 [wandb_init.py:init():1040] starting run threads in backend
2025-11-24 05:16:37,152 INFO    MainThread:88684 [wandb_run.py:_console_start():2504] atexit reg
2025-11-24 05:16:37,152 INFO    MainThread:88684 [wandb_run.py:_redirect():2352] redirect: wrap_raw
2025-11-24 05:16:37,152 INFO    MainThread:88684 [wandb_run.py:_redirect():2421] Wrapping output streams.
2025-11-24 05:16:37,153 INFO    MainThread:88684 [wandb_run.py:_redirect():2444] Redirects installed.
2025-11-24 05:16:37,157 INFO    MainThread:88684 [wandb_init.py:init():1080] run started, returning control to user process
2025-11-24 05:16:37,163 INFO    MainThread:88684 [wandb_run.py:_config_callback():1385] config_cb None None {'representation_epochs': 10, 'softmax_epochs': 10, 'train_batch_size': 512, 'device': 'cpu', 'cuda_available': True, 'cuda_device_name': None}
2025-11-24 05:29:38,575 INFO    MainThread:88684 [wandb_run.py:_finish():2270] finishing run aliphys-lu/SweepCUDA100+200/o7qtwnb2
2025-11-24 05:29:38,576 INFO    MainThread:88684 [wandb_run.py:_atexit_cleanup():2469] got exitcode: 0
2025-11-24 05:29:38,577 INFO    MainThread:88684 [wandb_run.py:_restore():2451] restore
2025-11-24 05:29:38,577 INFO    MainThread:88684 [wandb_run.py:_restore():2457] restore done
2025-11-24 05:29:40,102 INFO    MainThread:88684 [wandb_run.py:_footer_sync_info():3853] logging synced files
